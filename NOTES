In spvm_all or spvm, must allow for kernels with double arguments. 
That means I need if statements. 

Now that I subclass, I get an error with the double precision. WHY? 
Problem with destructor

----------------------------------------------------------------------
June 10, 2013
Cascade: cases 7,9,10 run without error. 
         case 5 has errors.  <<<<<

Frodo (MIC): cases 7,9,10 run without error. 
         case 5 has errors <<<<

Gordo_mac (GPU): cases 7,9,10 run without error. 
         case 5 has no errors

case5: method0, method1 work (on mac)
case5: method0, method1 work (on cascade)
----------------------------------------------------------------------
Run different cases: 
Stencils: 10, 32, 64
Single and double precision
On K-20 and mic
Using SPMV (ell,bell,spell,sell), ViennaCL, my OpenCL
Perhaps try a OpenMP implementation.
Single versus double precision. 

Compare with FD and spectral.: 
  Perhaps cost per point? 
  GFLOP ==> percentage of peak

Based on nb workgroups size. 
with and without vectorization (add pragma: vec_hint<double4> on MIC)

Study cost of memory transfers on the different architectures (user perspective)
Study use when combined with using the derivatives (which incures more memory bandwidth)
----------------------------------------------------------------------
CREATE: 

Data structure that contains all run parameters: 

  - input file
  - kernel file/name
  - float or double
  - work group and total number of threads
  - nb nodes in template
  - grid size
  - type of process (MIC, K20, TESLA, AMD) 
  - type of CPU (how to get this)
  - register analysis of rows (NEED CODE FOR THIS)
  - sparsity type (COMPACT, RANDOM)
  - whether or not matrix data has been reordered and the type
     (Cut-Hill-McGee, space-filling curve)
  - sparse matrix format: (ELL, SELL, SBELL, BELL, CVR)
----------------------------------------------------------------------
No need to run all cases (bell, sell, etc.) for all matrices. Choose 1-2 representative, 
say 32 nodes per stencil.  Choose only large node configurations where GPU is saturated. 
Later on, do some spot checks. 

Generate the 3D datasets. 
----------------------------------------------------------------------
works if I read ascii file, does not work if read binary  file. 

I am getting buffer errors. DO NOT KNOW WHY. 
----------------------------------------------------------------------
July 2, 2013
What does the error message:  "too large" mean? 
output/random_x_weights_direct__no_hv_stsize_33_3d_64x_64y_64z.mtxb_case10:SBELL too large totalsize 8421376 bwidth 8 bheight 8
----------------------------------------------------------------------
July 19, 2013
Method 7: correct results if matrix constant, and vector constant. I also made matrix m = m*matrix(0), with correct results. 
Now create matrix with constant vertical lines. Column i: value: i. Then do row i: value i.

My generation of col_ids is incorrect. When randomized and when I have only 32 columns, and the 
matrix has only 32 columns. CHECK GENERATING code in rbffd. 
----------------------------------------------------------------------
June 22, 2013
Errors solved. 
method_7a: 19 gflops
method_8a: 18 gflops
----------------------------------------------------------------------
July 26, 2013
I get 100 Gflops with 4 functions and 4 matrices with method8a. And generate the correct results. Grids of 
64^3 and beyond. Time changes depending on cache size. 
Must order the points on a row from smallest to largest (not yet down) for better efficiency and to be consistent with 
real stencils. 

Implement cuthill McGee within this program using ViennaCL. 

Tests: Cuthill McGee, Center diagonal control, outer diagonal control.  Array size. 

To implement: double precision and its relation to cache size. 

Calculation of maximum possible speed on the intel based on theoretical bandwidth and estimated number of times
a function is accessed. As a function of number of zeros and their distribution. Benchmark based on fraction of speed
relative to maximum possible for a particular algorithm (as opposed to maximum speed of the machine.)
----------------------------------------------------------------------
July 26, 2013
64^3, random_diag. Vary bandwidth (no outside diagonals)
bandwidth, Gflops
1000, 100
3000, 85
5000, 62
7000, 49
9000, 42
11000, 37
13000, 35
31000, 25

Now take inner_bandwidth of 2000 and vary outer diagonal only, from 4000 to 20000. 
I get for 64^3, 88 Gflops, independent of diagonal separation. 
----------------------------------------------------------------------
July 27, 2013
- rewrite base version with one matrix and 1 vector
- rewrite version with four matrices and 1 vector
- rewrite version with one matrix and 1 vector

Do this in single and double precision. 

Modify inner_bandwidth, number of diagonals
On GPU: fastest index is down the column (columnwise ordering for col_id)
OpenMP CPU: rowise ordering is best.
----------------------------------------------------------------------
